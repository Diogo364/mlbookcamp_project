{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 04\n",
    "---\n",
    "[mlbookcamp 04-evalutation](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/cohorts/2022/04-evaluation/homework.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRPATH=\"./data/\"\n",
    "FILENAME = \"CreditCard.csv\"\n",
    "DATAPATH = osp.join(DIRPATH, FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AER_credit_card_data.csv to ./data//CreditCard.csv\n",
      "--2022-10-03 09:02:22--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AER_credit_card_data.csv\n",
      "Resolvendo raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8001::154, 2606:50c0:8000::154, 2606:50c0:8003::154, ...\n",
      "Conectando-se a raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8001::154|:443... conectado.\n",
      "A requisição HTTP foi enviada, aguardando resposta... 200 OK\n",
      "Tamanho: 73250 (72K) [text/plain]\n",
      "Salvando em: “./data//CreditCard.csv”\n",
      "\n",
      "./data//CreditCard. 100%[===================>]  71,53K  --.-KB/s    em 0,03s   \n",
      "\n",
      "2022-10-03 09:02:23 (2,16 MB/s) - “./data//CreditCard.csv” salvo [73250/73250]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! ./downloading_data.sh -d $DIRPATH -f $FILENAME https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AER_credit_card_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "Code available at https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/04-evaluation/homework-4-starter.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>card</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reports</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>37.66667</td>\n",
       "      <td>33.25</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>30.5</td>\n",
       "      <td>32.16667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>4.52</td>\n",
       "      <td>2.42</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.54</td>\n",
       "      <td>9.7867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>share</th>\n",
       "      <td>0.03327</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>0.067051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenditure</th>\n",
       "      <td>124.9833</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>15.0</td>\n",
       "      <td>137.8692</td>\n",
       "      <td>546.5033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>owner</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selfemp</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dependents</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>months</th>\n",
       "      <td>54</td>\n",
       "      <td>34</td>\n",
       "      <td>58</td>\n",
       "      <td>25</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>majorcards</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4\n",
       "card              yes       yes       yes       yes       yes\n",
       "reports             0         0         0         0         0\n",
       "age          37.66667     33.25  33.66667      30.5  32.16667\n",
       "income           4.52      2.42       4.5      2.54    9.7867\n",
       "share         0.03327  0.005217  0.004156  0.065214  0.067051\n",
       "expenditure  124.9833  9.854167      15.0  137.8692  546.5033\n",
       "owner             yes        no       yes        no       yes\n",
       "selfemp            no        no        no        no        no\n",
       "dependents          3         3         4         0         2\n",
       "months             54        34        58        25        64\n",
       "majorcards          1         1         1         1         1\n",
       "active             12        13         5         7         5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATAPATH)\n",
    "data.columns = data.columns.str.lower()\n",
    "data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the target variable by mapping `yes` to `1` and `no` to `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_card = data.card == 'yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use train_test_split funciton for that with random_state=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns='card'),\n",
    "                                                    target_card,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train,\n",
    "                                                Y_train,\n",
    "                                                test_size=0.25,\n",
    "                                                random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6, 0.2, 0.2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round([len(X_train)/len(data), len(X_test)/len(data), len(X_val)/len(data)], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables.\n",
    "\n",
    "Let's do that\n",
    "\n",
    "- For each numerical variable, use it as score and compute AUC with the \"card\" variable\n",
    "- Use the training dataset for that\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. -df_train['expenditure'])\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "- `reports`\n",
    "- `dependents`\n",
    "- `active`\n",
    "- `share`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reports': 0.7166629860689376,\n",
       " 'dependents': 0.5327757227773791,\n",
       " 'active': 0.6043173411362006,\n",
       " 'share': 0.989183643423692}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "query_features = ['reports', 'dependents', 'active', 'share']\n",
    "dict_scores = {}\n",
    "for feature in query_features:\n",
    "    auc_score = roc_auc_score(Y_train, X_train[feature])\n",
    "    auc_score = auc_score if auc_score >= 0.5 else roc_auc_score(Y_train, -X_train[feature])\n",
    "    dict_scores[feature] = auc_score\n",
    "dict_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['share', 'reports', 'active', 'dependents']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dict_scores, key=dict_scores.get, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "From now on, use these columns only:\n",
    "    \n",
    "    [\"reports\", \"age\", \"income\", \"share\", \"expenditure\", \"dependents\", \"months\", \"majorcards\", \"active\", \"owner\", \"selfemp\"]\n",
    "\n",
    "Apply `one-hot-encoding` using `DictVectorizer` and train the logistic regression with these parameters:\n",
    "\n",
    "    LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columnns = [\"reports\", \"age\", \"income\", \"share\", \"expenditure\", \"dependents\", \"months\", \"majorcards\", \"active\", \"owner\", \"selfemp\"]\n",
    "\n",
    "X_train = X_train[feature_columnns]\n",
    "X_test = X_test[feature_columnns]\n",
    "X_val = X_val[feature_columnns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dict_vect = DictVectorizer(sparse=False)\n",
    "X_train_preprocessed = dict_vect.fit_transform(X_train.to_dict(orient='records'))\n",
    "X_test_preprocessed = dict_vect.transform(X_test.to_dict(orient='records'))\n",
    "X_val_preprocessed = dict_vect.transform(X_val.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "model.fit(X_train_preprocessed, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict_proba(X_val_preprocessed)[:, 1]\n",
    "round(roc_auc_score(Y_val, yhat), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "- Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "- For each threshold, compute precision and recall\n",
    "- Plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "yhat_proba = model.predict_proba(X_val_preprocessed)[:, 1]\n",
    "\n",
    "score_dict = {'threshold': [], 'precision': [], 'recall': []}\n",
    "\n",
    "for threshold in np.arange(0.0, 1.0, step=0.01):\n",
    "    yhat = (yhat_proba > threshold) * 1\n",
    "    score_dict['threshold'].append(threshold)\n",
    "    score_dict['precision'].append(precision_score(Y_val, yhat, zero_division=0.0))\n",
    "    score_dict['recall'].append(recall_score(Y_val, yhat, zero_division=.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_df = pd.DataFrame(score_dict).set_index('threshold')\n",
    "plt.plot(score_df.index, score_df.precision, label='PRECISION')\n",
    "plt.plot(score_df.index, score_df.recall, label='RECALL')\n",
    "plt.title('Precision x Recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "$$F_1 = 2 \\cdot \\cfrac{P \\cdot R}{P + R}$$\n",
    "\n",
    " \n",
    "Where `P` is precision and `R` is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At which threshold F1 is maximal?\n",
    "\n",
    "- `0.1`\n",
    "- `0.4`\n",
    "- `0.6`\n",
    "- `0.7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.36</th>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.41</th>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.37</th>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.38</th>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>0.905579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.03</th>\n",
       "      <td>0.897872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>0.871901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.861224</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.799242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision    recall        F1\n",
       "threshold                               \n",
       "0.35        0.995146  0.971564  0.983213\n",
       "0.36        0.995146  0.971564  0.983213\n",
       "0.41        0.995146  0.971564  0.983213\n",
       "0.37        0.995146  0.971564  0.983213\n",
       "0.38        0.995146  0.971564  0.983213\n",
       "...              ...       ...       ...\n",
       "0.04        0.905579  1.000000  0.950450\n",
       "0.03        0.897872  1.000000  0.946188\n",
       "0.02        0.871901  1.000000  0.931567\n",
       "0.01        0.861224  1.000000  0.925439\n",
       "0.00        0.799242  1.000000  0.888421\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df['F1'] = 2* (score_df.precision * score_df.recall) / (score_df.precision + score_df.recall)\n",
    "score_df.sort_values(by='F1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Use the KFold class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "    KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "- Iterate over different folds of df_full_train\n",
    "- Split the data into train and validation\n",
    "- Train the model on train with these parameters: `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
    "- Use AUC to evaluate the model on validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How large is standard devidation of the AUC scores across different folds?\n",
    "\n",
    "- `0.003`\n",
    "- `0.014`\n",
    "- `0.09`\n",
    "- `0.24`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_x_train = pd.concat([X_train, X_test, X_val])\n",
    "df_full_y_train = pd.concat([Y_train, Y_test, Y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "score_list = []\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "for train_idx, val_idx in kfold.split(df_full_x_train, df_full_y_train):\n",
    "    X_train = df_full_x_train.iloc[train_idx]\n",
    "    X_val = df_full_x_train.iloc[val_idx]\n",
    "    Y_train = df_full_y_train.iloc[train_idx]\n",
    "    Y_val = df_full_y_train.iloc[val_idx]\n",
    "    model.fit(dict_vect.fit_transform(X_train.to_dict(orient='records')), Y_train)\n",
    "    yhat = model.predict_proba(dict_vect.transform(X_val.to_dict(orient='records')))[:, 1]\n",
    "    score_list.append(roc_auc_score(Y_val, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9952082970814731, 0.004554857008222343)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score_list), np.std(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "- Iterate over the following C values: `[0.01, 0.1, 1, 10]`\n",
    "- Initialize KFold with the same parameters as previously\n",
    "- Use these parametes for the model: LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "- Compute the mean score as well as the std (round the mean and std to 3 decimal digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which C leads to the best mean score?\n",
    "\n",
    "- `0.01`\n",
    "- `0.1`\n",
    "- `1`\n",
    "- `10`\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>K</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.995256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.985697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.995929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.990740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.992311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.992724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C  K     score\n",
       "0    0.01  0  0.999897\n",
       "1    0.01  1  0.984469\n",
       "2    0.01  2  0.995256\n",
       "3    0.01  3  0.985697\n",
       "4    0.01  4  0.995929\n",
       "5    0.10  0  0.999897\n",
       "6    0.10  1  0.985069\n",
       "7    0.10  2  0.997628\n",
       "8    0.10  3  0.990740\n",
       "9    0.10  4  0.998255\n",
       "10   1.00  0  0.999897\n",
       "11   1.00  1  0.987695\n",
       "12   1.00  2  0.997551\n",
       "13   1.00  3  0.992311\n",
       "14   1.00  4  0.998588\n",
       "15  10.00  0  0.999897\n",
       "16  10.00  1  0.988670\n",
       "17  10.00  2  0.997781\n",
       "18  10.00  3  0.992724\n",
       "19  10.00  4  0.998504"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dict = {'C': [], 'K': [], 'score': []}\n",
    "\n",
    "for C in [0.01, 0.1, 1, 10]:\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    \n",
    "    for K, (train_idx, val_idx) in enumerate(kfold.split(df_full_x_train, df_full_y_train)):\n",
    "        X_train = df_full_x_train.iloc[train_idx]\n",
    "        X_val = df_full_x_train.iloc[val_idx]\n",
    "        Y_train = df_full_y_train.iloc[train_idx]\n",
    "        Y_val = df_full_y_train.iloc[val_idx]\n",
    "        \n",
    "        model.fit(dict_vect.fit_transform(X_train.to_dict(orient='records')), Y_train)\n",
    "        yhat = model.predict_proba(dict_vect.transform(X_val.to_dict(orient='records')))[:, 1]\n",
    "        \n",
    "        score_dict['C'].append(C)\n",
    "        score_dict['K'].append(K)\n",
    "        score_dict['score'].append(roc_auc_score(Y_val, yhat))\n",
    "\n",
    "score_df = pd.DataFrame(score_dict)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C   mean    std\n",
       "          score  score\n",
       "3  10.00  0.996  0.005\n",
       "2   1.00  0.995  0.005\n",
       "1   0.10  0.994  0.006\n",
       "0   0.01  0.992  0.007"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.pivot_table(index='C', values='score', aggfunc=['mean', 'std']).round(3).reset_index().sort_values(by=[('mean', 'score'), ('std', 'score'), 'C'], ascending=[False, False, True])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('general-conda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6c412e415f27236cb9d9dc68868e41cb65d54679c06807ebc8d62a20f3611d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
